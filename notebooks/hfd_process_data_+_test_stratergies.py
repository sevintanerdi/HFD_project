# -*- coding: utf-8 -*-
"""HFD process data + test stratergies.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-zB4sXZtvWYsYBYSsBINxRAE1Zazfjtu
"""

!git clone https://github.com/sevintanerdi/HFD_project.git

import pandas as pd
import numpy as np
import os

# Group 2 quarters
quarters = [
    "2023_Q1", "2023_Q3", "2023_Q4",
    "2024_Q2", "2024_Q4",
    "2025_Q1", "2025_Q2"
]

# Paths
input_dir = "HFD_project/data_raw/group2/"
output_dir = "HFD_project/data_processed/group2_processed/"
os.makedirs(output_dir, exist_ok=True)

# Process and save files
for q in quarters:
    df = pd.read_parquet(f"{input_dir}data2_{q}.parquet")

    # Set datetime index
    df["datetime"] = pd.to_datetime(df["datetime"])
    df.set_index("datetime", inplace=True)

    # Block trading from 16:50 to 18:10
    pos_flat = np.zeros(len(df))
    mask = (
        (df.index.time >= pd.to_datetime("16:50").time()) &
        (df.index.time <= pd.to_datetime("18:10").time())
    )
    pos_flat[mask] = 1
    df["pos_flat"] = pos_flat

    # Save processed file
    df.to_parquet(f"{output_dir}data2_{q}_processed.parquet")
    print(f"Saved: data2_{q}_processed.parquet")

# Validate processing
print("\nValidating Group 2 break-time rule\n")

for q in quarters:
    df = pd.read_parquet(f"{output_dir}data2_{q}_processed.parquet")
    df.index = pd.to_datetime(df.index)

    break_rows = df.between_time("16:50", "18:10")
    total = len(break_rows)
    correct = (break_rows["pos_flat"] == 1).sum()

    if total == correct:
        print(f"{q}: {correct}/{total} rows correctly masked")
    else:
        print(f"{q}: {correct}/{total} rows masked - ERROR")

!pip install quantstats

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import quantstats as qs

# global settings
quarters = [
    "2023_Q1", "2023_Q3", "2023_Q4",
    "2024_Q2", "2024_Q4",
    "2025_Q1", "2025_Q2"
]

POINT_VALUE = 100
TCOST = 15

# Sharpe ratio function
def mySR(x, scale):
    return np.sqrt(scale) * np.nanmean(x) / np.nanstd(x)

# summary container
summary_group2_all = pd.DataFrame()

# EMA momentum strategy
for quarter in quarters:

    data = pd.read_parquet(
        f"HFD_project/data_processed/group2_processed/data2_{quarter}_processed.parquet"
    )

    pos_flat = data["pos_flat"].values

    for fast, slow in [(10, 60), (20, 100)]:

        fastEMA = data["XAU"].ewm(span=fast).mean()
        slowEMA = data["XAU"].ewm(span=slow).mean()

        fastEMA[data["XAU"].isna()] = np.nan
        slowEMA[data["XAU"].isna()] = np.nan

        cond_long = fastEMA.shift(1) > slowEMA.shift(1)
        valid = fastEMA.shift(1).notna() & slowEMA.shift(1).notna()

        pos = np.where(valid, np.where(cond_long, 1, -1), np.nan)
        pos[pos_flat == 1] = 0

        pnl_gross = np.where(
            np.isnan(pos * data["XAU"].diff()),
            0,
            pos * data["XAU"].diff() * POINT_VALUE
        )

        pnl_gross_pct = pnl_gross / data["XAU"].shift(1)

        ntrans = np.abs(np.diff(pos, prepend=0))
        pnl_net = pnl_gross - ntrans * TCOST
        pnl_net_pct = pnl_net / data["XAU"].shift(1)

        pnl_gross_d = pd.Series(pnl_gross).groupby(data.index.date).sum()
        pnl_net_d = pd.Series(pnl_net).groupby(data.index.date).sum()
        pnl_gross_pct_d = pnl_gross_pct.groupby(data.index.date).sum()
        pnl_net_pct_d = pnl_net_pct.groupby(data.index.date).sum()
        ntrans_d = pd.Series(ntrans).groupby(data.index.date).sum()

        gross_SR = mySR(pnl_gross_d, 252)
        net_SR = mySR(pnl_net_d, 252)
        gross_CR = qs.stats.calmar(pnl_gross_pct_d.dropna())
        net_CR = qs.stats.calmar(pnl_net_pct_d.dropna())

        stat = (net_SR - 0.5) * np.maximum(0, np.log(np.abs(pnl_net_d.sum() / 1000)))

        summary = pd.DataFrame({
            "quarter": quarter,
            "strategy": "momentum",
            "params": f"EMA{fast}-{slow}",
            "gross_SR": gross_SR,
            "net_SR": net_SR,
            "gross_PnL": pnl_gross_d.sum(),
            "net_PnL": pnl_net_d.sum(),
            "gross_CR": gross_CR,
            "net_CR": net_CR,
            "av_daily_ntrans": ntrans_d.mean(),
            "stat": stat
        }, index=[0])

        summary_group2_all = pd.concat(
            [summary_group2_all, summary],
            ignore_index=True
        )

        plt.figure(figsize=(12, 6))
        plt.plot(np.cumsum(pnl_gross_d.fillna(0)))
        plt.plot(np.cumsum(pnl_net_d.fillna(0)))
        plt.title(f"XAU Momentum EMA{fast}-{slow} {quarter}")
        plt.grid()
        plt.savefig(f"XAU_momentum_EMA{fast}_{slow}_{quarter}.png", dpi=300)
        plt.close()

# mean-reversion strategy
for quarter in quarters:

    data = pd.read_parquet(
        f"HFD_project/data_processed/group2_processed/data2_{quarter}_processed.parquet"
    )

    pos_flat = data["pos_flat"].values

    for window, k in [(20, 1.5), (50, 2.0)]:

        mean = data["XAU"].rolling(window).mean()
        std = data["XAU"].rolling(window).std()

        upper = mean + k * std
        lower = mean - k * std

        valid = mean.shift(1).notna()

        pos = np.where(
            valid,
            np.where(
                data["XAU"].shift(1) < lower.shift(1), 1,
                np.where(
                    data["XAU"].shift(1) > upper.shift(1), -1,
                    0
                )
            ),
            np.nan
        )

        pos[pos_flat == 1] = 0

        pnl_gross = np.where(
            np.isnan(pos * data["XAU"].diff()),
            0,
            pos * data["XAU"].diff() * POINT_VALUE
        )

        pnl_gross_pct = pnl_gross / data["XAU"].shift(1)

        ntrans = np.abs(np.diff(pos, prepend=0))
        pnl_net = pnl_gross - ntrans * TCOST
        pnl_net_pct = pnl_net / data["XAU"].shift(1)

        pnl_gross_d = pd.Series(pnl_gross).groupby(data.index.date).sum()
        pnl_net_d = pd.Series(pnl_net).groupby(data.index.date).sum()
        pnl_gross_pct_d = pnl_gross_pct.groupby(data.index.date).sum()
        pnl_net_pct_d = pnl_net_pct.groupby(data.index.date).sum()
        ntrans_d = pd.Series(ntrans).groupby(data.index.date).sum()

        gross_SR = mySR(pnl_gross_d, 252)
        net_SR = mySR(pnl_net_d, 252)
        gross_CR = qs.stats.calmar(pnl_gross_pct_d.dropna())
        net_CR = qs.stats.calmar(pnl_net_pct_d.dropna())

        stat = (net_SR - 0.5) * np.maximum(
            0, np.log(np.abs(pnl_net_d.sum() / 1000))
        )

        summary = pd.DataFrame({
            "quarter": quarter,
            "strategy": "mean_reversion",
            "params": f"win{window}_k{k}",
            "gross_SR": gross_SR,
            "net_SR": net_SR,
            "gross_PnL": pnl_gross_d.sum(),
            "net_PnL": pnl_net_d.sum(),
            "gross_CR": gross_CR,
            "net_CR": net_CR,
            "av_daily_ntrans": ntrans_d.mean(),
            "stat": stat
        }, index=[0])

        summary_group2_all = pd.concat(
            [summary_group2_all, summary],
            ignore_index=True
        )

        plt.figure(figsize=(12, 6))
        plt.plot(np.cumsum(pnl_gross_d.fillna(0)))
        plt.plot(np.cumsum(pnl_net_d.fillna(0)))
        plt.title(f"XAU Mean Reversion win{window} k{k} {quarter}")
        plt.grid()
        plt.savefig(f"XAU_meanrev_{window}_{k}_{quarter}.png", dpi=300)
        plt.close()

# Mean reversion strategy with exit at mean
for quarter in quarters:

    data = pd.read_parquet(
        f"HFD_project/data_processed/group2_processed/data2_{quarter}_processed.parquet"
    )

    pos_flat = data["pos_flat"].values

    for window, k in [(20, 1.5), (50, 2.0)]:

        mean = data["XAU"].rolling(window).mean()
        std = data["XAU"].rolling(window).std()

        upper = mean + k * std
        lower = mean - k * std

        valid = mean.shift(1).notna()

        pos = np.zeros(len(data))

        pos[(valid) & (data["XAU"].shift(1) < lower.shift(1))] = 1
        pos[(valid) & (data["XAU"].shift(1) > upper.shift(1))] = -1
        pos[(valid) & (data["XAU"].shift(1) >= mean.shift(1)) &
            (data["XAU"].shift(2) < mean.shift(2))] = 0
        pos[(valid) & (data["XAU"].shift(1) <= mean.shift(1)) &
            (data["XAU"].shift(2) > mean.shift(2))] = 0

        pos = pd.Series(pos).replace(0, np.nan).ffill().fillna(0).values
        pos[pos_flat == 1] = 0

        pnl_gross = np.where(
            np.isnan(pos * data["XAU"].diff()),
            0,
            pos * data["XAU"].diff() * POINT_VALUE
        )

        pnl_gross_pct = pnl_gross / data["XAU"].shift(1)

        ntrans = np.abs(np.diff(pos, prepend=0))
        pnl_net = pnl_gross - ntrans * TCOST
        pnl_net_pct = pnl_net / data["XAU"].shift(1)

        pnl_gross_d = pd.Series(pnl_gross).groupby(data.index.date).sum()
        pnl_net_d = pd.Series(pnl_net).groupby(data.index.date).sum()
        pnl_gross_pct_d = pnl_gross_pct.groupby(data.index.date).sum()
        pnl_net_pct_d = pnl_net_pct.groupby(data.index.date).sum()
        ntrans_d = pd.Series(ntrans).groupby(data.index.date).sum()

        gross_SR = mySR(pnl_gross_d, 252)
        net_SR = mySR(pnl_net_d, 252)
        gross_CR = qs.stats.calmar(pnl_gross_pct_d.dropna())
        net_CR = qs.stats.calmar(pnl_net_pct_d.dropna())

        stat = (net_SR - 0.5) * np.maximum(
            0, np.log(np.abs(pnl_net_d.sum() / 1000))
        )

        summary = pd.DataFrame({
            "quarter": quarter,
            "strategy": "mean_reversion",
            "params": f"win{window}_k{k}_exitMean",
            "gross_SR": gross_SR,
            "net_SR": net_SR,
            "gross_PnL": pnl_gross_d.sum(),
            "net_PnL": pnl_net_d.sum(),
            "gross_CR": gross_CR,
            "net_CR": net_CR,
            "av_daily_ntrans": ntrans_d.mean(),
            "stat": stat
        }, index=[0])

        summary_group2_all = pd.concat(
            [summary_group2_all, summary],
            ignore_index=True
        )

        plt.figure(figsize=(12, 6))
        plt.plot(np.cumsum(pnl_gross_d.fillna(0)))
        plt.plot(np.cumsum(pnl_net_d.fillna(0)))
        plt.title(f"XAU Mean Reversion (exit at mean) {quarter}")
        plt.grid()
        plt.savefig(f"XAU_meanrev_exitMean_{window}_{k}_{quarter}.png", dpi=300)
        plt.close()

print(summary_group2_all)

best = (
    summary_group2_all
    .groupby(["strategy", "params"], as_index=False)["stat"]
    .sum()
    .sort_values("stat", ascending=False)
)

best